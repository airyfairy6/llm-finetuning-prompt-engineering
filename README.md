<p align="center">
  <img src="assets/LLM Fine-Tuning Workflow Diagram.png" width="700" />
</p>
## ðŸ§± Architecture Diagram

![Architecture Diagram](assets/architecture_diagram.png)
# llm-finetuning-prompt-engineering
LLM Prompt Engineering & Fine-Tuning Project

This repository showcases hands-on experience with LLM prompt engineering, model fine-tuning, and toxicity reduction, developed through three practical labs:

1.Dialogue Summarization Using Prompt Engineering.
Goal:Transform messy, conversation-style text into clear, structured summaries using LLM prompt patterns.
Techniques used:
Instruction prompting
Condense / rewrite / extract patterns
Bullet-point vs. narrative summarization
Style- and length-controlled prompts

2.Fine-Tuning a Generative AI Model on Custom Data.
Goal:Improve output quality by fine-tuning a generative model with input/output training pairs.
Stages:
Preparing fine-tuning data in JSONL format
Training using the OpenAI fine-tuning API (or simulation)
Evaluating pre- vs post-fine-tune behavior
Adjusting hyperparameters
Understanding model behavior changes after training

3.Detoxifying Model Outputs Through Supervised Fine-Tuning
Goal:Make model outputs safer by fine-tuning on examples of toxic vs. non-toxic rewrites.
Technics:
Safety alignment
Ethical AI concepts
Creating supervised training pairs
Evaluating toxicity reduction
Maintaining meaning while improving tone

Together, the labs demonstrate real-world skills used in Model Development, Applied NLP, and LLM Engineering roles, including prompt optimization, dataset preparation, fine-tuning workflows, and evaluation techniques.
